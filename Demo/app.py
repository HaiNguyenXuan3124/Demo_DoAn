import streamlit as st
import joblib
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Load mÃ´ hÃ¬nh vÃ  cÃ¡c thÃ nh pháº§n liÃªn quan
model = load_model("Saved_model_LSTM500000.h5")
tokenizer = joblib.load("tokenizer_500000.pkl")
label_encoder = joblib.load("label_encoder_500000.pkl")
max_len = joblib.load("max_len_500000.pkl")

# Giao diá»‡n ngÆ°á»i dÃ¹ng
st.set_page_config(page_title="Dá»± Ä‘oÃ¡n cáº£m xÃºc", layout="centered")
st.title("ğŸ“¢ PhÃ¢n tÃ­ch cáº£m xÃºc Ä‘Ã¡nh giÃ¡ khÃ¡ch sáº¡n (LSTM)")

text_input = st.text_area("âœï¸ Nháº­p Ä‘Ã¡nh giÃ¡ (tiáº¿ng Anh):", height=150)

if st.button("Dá»± Ä‘oÃ¡n"):
    if not text_input.strip():
        st.warning("Vui lÃ²ng nháº­p ná»™i dung.")
    else:
        # Xá»­ lÃ½ Ä‘áº§u vÃ o
        seq = tokenizer.texts_to_sequences([text_input])
        pad = pad_sequences(seq, maxlen=max_len)

        # Dá»± Ä‘oÃ¡n
        pred_proba = model.predict(pad)[0]
        pred_class = np.argmax(pred_proba)
        label = label_encoder.inverse_transform([pred_class])[0]

        st.success(f"Káº¿t quáº£ dá»± Ä‘oÃ¡n: **{label}**")
        st.write(f"ğŸ” XÃ¡c suáº¥t: {pred_proba}")
